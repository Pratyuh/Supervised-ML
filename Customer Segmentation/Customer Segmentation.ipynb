{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('data/sample_submission_wyi0h0z.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8068, 11), (2627, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['Segmentation'] = le.fit_transform(train['Segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL, TARGET_COL = 'ID', 'Segmentation'\n",
    "features = [c for c in train.columns if c not in [ID_COL, TARGET_COL]]\n",
    "\n",
    "cat_cols = ['Gender',\n",
    " 'Ever_Married',\n",
    " 'Graduated',\n",
    " 'Profession',\n",
    " 'Spending_Score',\n",
    " 'Var_1']\n",
    "\n",
    "num_cols = [c for c in features if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_preds(preds_test, file_name = 'cust_seg.csv'):\n",
    "    \n",
    "\n",
    "  ## 1. Setting the target column with our obtained predictions\n",
    "      ss[TARGET_COL] = preds_test\n",
    "    \n",
    "      ss[TARGET_COL] = le.inverse_transform(ss[TARGET_COL])\n",
    "    \n",
    "\n",
    "\n",
    "  ## 2. Saving our predictions to a csv file\n",
    "\n",
    "      ss.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10695, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train, test], axis=0).reset_index(drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0   \n",
       "Age                         0   \n",
       "Work_Experience             1098\n",
       "Family_Size                 448 \n",
       "Segmentation                2627\n",
       "Gender_Female               0   \n",
       "Gender_Male                 0   \n",
       "Ever_Married_No             0   \n",
       "Ever_Married_Yes            0   \n",
       "Graduated_No                0   \n",
       "Graduated_Yes               0   \n",
       "Profession_Artist           0   \n",
       "Profession_Doctor           0   \n",
       "Profession_Engineer         0   \n",
       "Profession_Entertainment    0   \n",
       "Profession_Executive        0   \n",
       "Profession_Healthcare       0   \n",
       "Profession_Homemaker        0   \n",
       "Profession_Lawyer           0   \n",
       "Profession_Marketing        0   \n",
       "Spending_Score_Average      0   \n",
       "Spending_Score_High         0   \n",
       "Spending_Score_Low          0   \n",
       "Var_1_Cat_1                 0   \n",
       "Var_1_Cat_2                 0   \n",
       "Var_1_Cat_3                 0   \n",
       "Var_1_Cat_4                 0   \n",
       "Var_1_Cat_5                 0   \n",
       "Var_1_Cat_6                 0   \n",
       "Var_1_Cat_7                 0   \n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Work_Experience'] = df['Work_Experience'].fillna(df['Work_Experience'].median())\n",
    "df['Family_Size'] = df['Family_Size'].fillna(df['Family_Size'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0   \n",
       "Age                         0   \n",
       "Work_Experience             0   \n",
       "Family_Size                 0   \n",
       "Segmentation                2627\n",
       "Gender_Female               0   \n",
       "Gender_Male                 0   \n",
       "Ever_Married_No             0   \n",
       "Ever_Married_Yes            0   \n",
       "Graduated_No                0   \n",
       "Graduated_Yes               0   \n",
       "Profession_Artist           0   \n",
       "Profession_Doctor           0   \n",
       "Profession_Engineer         0   \n",
       "Profession_Entertainment    0   \n",
       "Profession_Executive        0   \n",
       "Profession_Healthcare       0   \n",
       "Profession_Homemaker        0   \n",
       "Profession_Lawyer           0   \n",
       "Profession_Marketing        0   \n",
       "Spending_Score_Average      0   \n",
       "Spending_Score_High         0   \n",
       "Spending_Score_Low          0   \n",
       "Var_1_Cat_1                 0   \n",
       "Var_1_Cat_2                 0   \n",
       "Var_1_Cat_3                 0   \n",
       "Var_1_Cat_4                 0   \n",
       "Var_1_Cat_5                 0   \n",
       "Var_1_Cat_6                 0   \n",
       "Var_1_Cat_7                 0   \n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the processed dataset back into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop = True)\n",
    "\n",
    "features = [c for c in train_proc.columns if c not in [ID_COL, TARGET_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc[TARGET_COL] = train_proc[TARGET_COL].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split the train set into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train_proc, test_size=0.2, random_state = 1, stratify = train_proc[TARGET_COL])\n",
    "\n",
    "###### Input to our model will be the features\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "###### Output of our model will be the TARGET_COL\n",
    "y_trn, y_val = trn[TARGET_COL], val[TARGET_COL]\n",
    "\n",
    "##### Features for the test data that we will be predicting\n",
    "X_test = test_proc[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(X_trn)\n",
    "\n",
    "X_trn = scaler.transform(X_trn)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5061957868649318"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state = 1,multi_class=\"auto\")\n",
    "_ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "download_preds(preds_test, file_name='hacklive_logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4318463444857497"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 1)\n",
    "_ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "download_preds(preds_test, file_name='hacklive_decision_tree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48141263940520446"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1,n_estimators=500)\n",
    "_ = clf._ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "download_preds(preds_test, file_name='hacklive_random_tree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 30,\n",
       " 'max_leaf_nodes': 32,\n",
       " 'max_features': 0.8,\n",
       " 'max_depth': 8,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "hyperparam_combs = {\n",
    "    'max_depth': [4, 6, 8, 10, 12],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 10, 20, 30, 40],\n",
    "    'max_features': [0.2, 0.4, 0.6, 0.8, 1],\n",
    "    'max_leaf_nodes': [8, 16, 32, 64, 128]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                         hyperparam_combs,\n",
    "                         random_state=1,\n",
    "                         n_iter=20)\n",
    "\n",
    "search = clf.fit(train_proc[features], train_proc[TARGET_COL])\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5216852540272615"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_params = {'min_samples_split': 30,\n",
    " 'max_leaf_nodes': 32,\n",
    " 'max_features': 0.8,\n",
    " 'max_depth': 8,\n",
    " 'criterion': 'entropy'}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 1, **optimal_params)\n",
    "_ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "\n",
    "download_preds(preds_test, file_name = 'hacklive_dt_tuned_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf_kfold(clf, train, test, features):\n",
    "\n",
    "  N_SPLITS = 5\n",
    "\n",
    "  oofs = np.zeros(len(train))\n",
    "  preds = np.zeros((len(test)))\n",
    "\n",
    "  folds = StratifiedKFold(n_splits = N_SPLITS)\n",
    "\n",
    "  for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train[TARGET_COL])):\n",
    "    print(f'\\n------------- Fold {fold_ + 1} -------------')\n",
    "\n",
    "    ############# Get train, validation and test sets along with targets ################\n",
    "  \n",
    "    ### Training Set\n",
    "    X_trn, y_trn = train[features].iloc[trn_idx], target.iloc[trn_idx]\n",
    "\n",
    "    ### Validation Set\n",
    "    X_val, y_val = train[features].iloc[val_idx], target.iloc[val_idx]\n",
    "\n",
    "    ### Test Set\n",
    "    X_test = test[features]\n",
    "\n",
    "    ############# Scaling Data ################\n",
    "    scaler = StandardScaler()\n",
    "    _ = scaler.fit(X_trn)\n",
    "\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    ############# Fitting and Predicting ################\n",
    "\n",
    "    _ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "    ### Instead of directly predicting the classes we will obtain the probability of positive class.\n",
    "#     preds_val = clf.predict_proba(X_val)[:, 1]\n",
    "#     preds_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    preds_val = clf.predict(X_val)\n",
    "    preds_test = clf.predict(X_test)\n",
    "    \n",
    "    fold_score = accuracy_score(y_val, preds_val)\n",
    "    print(f'\\naccuracy score for validation set is {fold_score}')\n",
    "\n",
    "    oofs[val_idx] = preds_val\n",
    "    preds += preds_test / N_SPLITS\n",
    "\n",
    "\n",
    "  oofs_score = accuracy_score(y_val, preds_val)\n",
    "  print(f'\\n\\naccuracy score for oofs is {oofs_score}')\n",
    "\n",
    "  return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "8063    3\n",
       "8064    3\n",
       "8065    3\n",
       "8066    1\n",
       "8067    1\n",
       "Name: Segmentation, Length: 8068, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train[TARGET_COL]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Fold 1 -------------\n",
      "\n",
      "accuracy score for validation set is 0.5328376703841388\n",
      "\n",
      "------------- Fold 2 -------------\n",
      "\n",
      "accuracy score for validation set is 0.4950433705080545\n",
      "\n",
      "------------- Fold 3 -------------\n",
      "\n",
      "accuracy score for validation set is 0.5130111524163569\n",
      "\n",
      "------------- Fold 4 -------------\n",
      "\n",
      "accuracy score for validation set is 0.536887786732796\n",
      "\n",
      "------------- Fold 5 -------------\n",
      "\n",
      "accuracy score for validation set is 0.5244885306881587\n",
      "\n",
      "\n",
      "accuracy score for oofs is 0.5244885306881587\n"
     ]
    }
   ],
   "source": [
    "dt_params = {'min_samples_split': 30,\n",
    " 'max_leaf_nodes': 32,\n",
    " 'max_features': 0.8,\n",
    " 'max_depth': 8,\n",
    " 'criterion': 'entropy'}\n",
    "\n",
    "clf = DecisionTreeClassifier(**dt_params)\n",
    "        \n",
    "\n",
    "dt_oofs, dt_preds = run_clf_kfold(clf, train_proc, test_proc, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5371747211895911"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf =  LGBMClassifier()\n",
    "_ = clf._ = clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "\n",
    "download_preds(preds_test, file_name = 'hacklive__lgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
